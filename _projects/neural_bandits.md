---
title: "[WIP] Active Learning with Neural Bandits"
collection: projects
permalink: /projects/neural_bandits
except: 'In the process of publishing this work to AAAI 2024. Hope to post the abstract soon!'
#excerpt: 'We study both stream-based and pool-based active learning with neural network approximations. A recent line of works proposed bandit-based approaches that transform active learning into a bandit problem, achieving both theoretical and empirical success. However, the type of methods incur the additional computational cost that is scaled by the number of classes $K$ due to this transformation. In contrast, the classic active learning algorithms will not be burdened by the extra computational cost, but they lack the principled exploration and provable performance guarantee compared to bandit-based methods. Therefore, this paper seeks to answer the question: "{\em How can we remove this incurred computation burden while still enjoying the principled exploration and provable performance guarantee for active learning?}" We propose two algorithms based on the newly designed exploitation and exploration neural networks for stream-based and pool-based active learning respectively. Then, we provide the theoretical performance guarantee for these two algorithms in the non-parametric setting by removing the dependency on function class radius. In the end, we use extensive experiments to evaluate the proposed algorithms, which consistently outperform state-of-the-art baselines.'
date: 2023-05-07
paperurl: 'http://agarwalishika.github.io/files/wip_sorry.pdf'
authors: 'Ishika Agarwal, Yikun Ban, Hanghang Tong'
---
In the process of publishing this work to AAAI 2024. Hope to post the abstract soon!

[Download paper here](http://agarwalishika.github.io/files/wip_sorry.pdf)
